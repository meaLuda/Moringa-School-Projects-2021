{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FuA5mWk3Jmdi"
      },
      "source": [
        "# Image Prediction With NeuralNetwork\n",
        "\n",
        "```\n",
        "The goal of this project is to train a regression Neural Network to predict the value \n",
        "of a pixel I(x, y) given its coordinates (x,y). We will use the square loss functions on\n",
        "the training examples (z;, ys, I(z:,¥:)),4 = 1,...,n:\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "a) Train a NN with one hidden layer containing 128 neurons, followed by ReLU.\n",
        "Train the NN for 300 epochs using the square loss \n",
        "    (1). Use the SGD optimizer\n",
        "with minibatch size 64, and an appropriate learning rate (e.g. 0.003). \n",
        "Reduce the learning rate to half every 100 epochs. Show a plot of the loss function vs epoch\n",
        "number. Display the image reconstructed from the trained NN fy (4,7),7 €\n",
        "{1,...,84},5 € {1,...,128}. (2 points)\n",
        "\n",
        "b) Repeat point a) with a NN with two hidden layers, first one with 32 neurons and\n",
        "second one with 128 neurons, each followed by ReLU. (2 points)\n",
        "\n",
        "c) Repeat point a) with a NN with three hidden layers, with 32, 64 and 128 neurons\n",
        "respectively, each followed by ReLU. (2 points)\n",
        "\n",
        "d) Repeat point a) with a NN with four hidden layers, with 32, 64, 128 and 128\n",
        "neurons respectively, each followed by ReLU. (3 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccitHwVSLHLm"
      },
      "source": [
        "# Helper Codes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhrfigJgJglO"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odd34Ob7ZTKi"
      },
      "outputs": [],
      "source": [
        "# Load the image\n",
        "img = Image.open('horse.jpg')\n",
        "img = img.convert('L')  # convert to grayscale\n",
        "img = img.resize((128, 84))  # resize\n",
        "pixels = img.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIVyLFoyRVbM"
      },
      "outputs": [],
      "source": [
        "# neural network models. \n",
        "def create_model(num_layers, hidden_sizes):\n",
        "    layers = []\n",
        "    in_size = 2\n",
        "    for i in range(num_layers):\n",
        "        layers.append(nn.Linear(in_size, hidden_sizes[i]))\n",
        "        layers.append(nn.ReLU())\n",
        "        in_size = hidden_sizes[i]\n",
        "    layers.append(nn.Linear(in_size, 1))\n",
        "    model = nn.Sequential(*layers)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXj6owFThJ2X"
      },
      "outputs": [],
      "source": [
        "# Define the training loop\n",
        "def train_model(model, train_loader, num_epochs, learning_rate):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 100 or epoch == 200:\n",
        "            learning_rate /= 2\n",
        "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "        epoch_loss = 0.0\n",
        "        # print(len(train_loader))\n",
        "        for inputs, labels in enumerate(train_loader, 0):\n",
        "            print(inputs)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs,labels)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            losses.append(epoch_loss)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")\n",
        "            return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgY2R1kyhJ0J"
      },
      "outputs": [],
      "source": [
        "# Create the training data\n",
        "train_data = []\n",
        "for i in range(84):\n",
        "    for j in range(128):\n",
        "        train_data.append(((i+1)/84, (j+1)/128, pixels[j, i]/255))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XADToCw2r-DK"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkGB86D5hJxY",
        "outputId": "0616c49d-9f96-410f-eab7-b4d8fcc6c5b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.011904761904761904, 0.0078125, 1.0),\n",
              " (0.011904761904761904, 0.015625, 1.0),\n",
              " (0.011904761904761904, 0.0234375, 1.0),\n",
              " (0.011904761904761904, 0.03125, 1.0),\n",
              " (0.011904761904761904, 0.0390625, 1.0),\n",
              " (0.011904761904761904, 0.046875, 1.0),\n",
              " (0.011904761904761904, 0.0546875, 1.0),\n",
              " (0.011904761904761904, 0.0625, 1.0),\n",
              " (0.011904761904761904, 0.0703125, 1.0),\n",
              " (0.011904761904761904, 0.078125, 1.0)]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSVFGO8piX-F"
      },
      "outputs": [],
      "source": [
        "# Train model with one hidden layer\n",
        "model1 = create_model(1, [128])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk0r4x4_rezk",
        "outputId": "8cac9073-1414-48a7-80fb-bc41f11f2ac8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD0pugfiPFO3"
      },
      "source": [
        "# Question A."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dst-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "5534083f2ecd8339f193f7c8a093319d8668f344ec14843698157086390717a2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
